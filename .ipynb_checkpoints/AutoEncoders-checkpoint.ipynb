{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommeder System using AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.read_csv(\"u1.base\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=pd.read_csv(\"u1.test\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users=max(max(training[0]),max(testing[0]))\n",
    "nb_movies=max(max(training[1]),max(testing[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=training.values\n",
    "testing=testing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         6,         5, 887431973],\n",
       "       [        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatrix(data):\n",
    "    result=np.zeros((nb_users,nb_movies),dtype=\"int\")\n",
    "    for row in data:\n",
    "        result[row[0]-1,row[1]-1]=row[2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_matrix=convertMatrix(training)\n",
    "testing_matrix=convertMatrix(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=torch.FloatTensor(training_matrix)\n",
    "testing_set=torch.FloatTensor(testing_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL model building\n",
    "- output_layer don't use activation_layer\n",
    "- Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Auto Encoders\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE,self).__init__() #super constructure\n",
    "        # 權重加成其實是一種線性轉換 # first hidden_layer is fully connected layer, fc value is the function\n",
    "        # hidden_layer catch the feature\n",
    "        self.fc1=nn.Linear(nb_movies,20) \n",
    "        self.fc2=nn.Linear(20,10)\n",
    "        self.fc3=nn.Linear(10,20)# 做 decoding 不能一次提升到與原本的input_vector 同維\n",
    "        self.fc4=nn.Linear(20,nb_movies) \n",
    "        self.activation = nn.Sigmoid() # 這也是個funciton\n",
    "    def forward(self,x):\n",
    "        x=self.activation(self.fc1(x))\n",
    "        x=self.activation(self.fc2(x))\n",
    "        x=self.activation(self.fc3(x))\n",
    "        x=self.fc4(x) # 在 output_layer 不用加入 activation_layer, autoencoder 特有結構\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae=SAE()\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "# let whole the data flow(including flow) data to the NN model \n",
    "# weight_decay's goal is reducing the learning rate after each epochs\n",
    "optimizer=optim.RMSprop(sae.parameters(),lr=0.01,weight_decay=0.5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Stacked AutoEncoders\n",
    "- reinforcement learning one-one training\n",
    "-step1. add batch dimension through Varaible.unsqueeze(0)\n",
    "- step2 : keep ratings>0 (meaningful for computing loss)\n",
    "- step3 forward and keep unrated ratings\n",
    "- step4. back probagation:\n",
    "    - Define the loss adjust the mean_coorerector\n",
    "    - loss.backward():direction\n",
    "    - compute train_loss=loss.data[0]*mean_corrector\n",
    "    - optimizer.step(): extent\n",
    "- step5. run each Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 training_loss 1.7717011619368186\n",
      "epoch 2 training_loss 1.0967046489917436\n",
      "epoch 3 training_loss 1.0534134210133272\n",
      "epoch 4 training_loss 1.038301281021026\n",
      "epoch 5 training_loss 1.030988528330219\n",
      "epoch 6 training_loss 1.026746183051177\n",
      "epoch 7 training_loss 1.0239013498198752\n",
      "epoch 8 training_loss 1.022124156843972\n",
      "epoch 9 training_loss 1.020716860819354\n",
      "epoch 10 training_loss 1.0197789375738373\n",
      "epoch 11 training_loss 1.0188899013414843\n",
      "epoch 12 training_loss 1.0183399449120867\n",
      "epoch 13 training_loss 1.0182607417767797\n",
      "epoch 14 training_loss 1.0178128668791449\n",
      "epoch 15 training_loss 1.0174139604980172\n",
      "epoch 16 training_loss 1.01707094876522\n",
      "epoch 17 training_loss 1.0167653622479542\n",
      "epoch 18 training_loss 1.0164899537643575\n",
      "epoch 19 training_loss 1.0164059346424372\n",
      "epoch 20 training_loss 1.0164015720556823\n",
      "epoch 21 training_loss 1.016093860805349\n",
      "epoch 22 training_loss 1.0160445219610368\n",
      "epoch 23 training_loss 1.0160665467524737\n",
      "epoch 24 training_loss 1.015956839543804\n",
      "epoch 25 training_loss 1.015594816622882\n",
      "epoch 26 training_loss 1.0156305178792895\n",
      "epoch 27 training_loss 1.0153106495540143\n",
      "epoch 28 training_loss 1.0151318921595687\n",
      "epoch 29 training_loss 1.0128915296237009\n",
      "epoch 30 training_loss 1.0120415585288187\n",
      "epoch 31 training_loss 1.009905944968857\n",
      "epoch 32 training_loss 1.0095949908191562\n",
      "epoch 33 training_loss 1.0053533914964328\n",
      "epoch 34 training_loss 1.0060100221075834\n",
      "epoch 35 training_loss 1.0012603694856221\n",
      "epoch 36 training_loss 1.0001329086342767\n",
      "epoch 37 training_loss 0.9985137473399326\n",
      "epoch 38 training_loss 0.9962647381056092\n",
      "epoch 39 training_loss 0.9922612352830014\n",
      "epoch 40 training_loss 0.9913096977722876\n"
     ]
    }
   ],
   "source": [
    "n_epochs=40\n",
    "result=[]\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    training_loss=0.0\n",
    "    s=0.0\n",
    "    for id_users in range(nb_users):\n",
    "        input_=Variable(training_set[id_users]).unsqueeze(0) # add 'one' dimension batch_size\n",
    "        target=input_.clone()\n",
    "        if torch.sum(target.data>0) > 0: # optimize the memory\n",
    "            output = sae(input_)\n",
    "            target.require_grad=False \n",
    "            result.append(output)\n",
    "            output[target==0]=0\n",
    "            \n",
    "            loss=criterion(output,target)\n",
    "            mean_corrector = nb_movies / float(torch.sum(target.data>0)+1e-10) # avoid inf error and adjust total error\n",
    "            loss.backward() \n",
    "            training_loss+=np.sqrt(loss.data[0]*mean_corrector) # loss.data is the MSE square \n",
    "            s+=1.0\n",
    "            \n",
    "            optimizer.step() # auto-diffentiation\n",
    "    \n",
    "    print(\"epoch\",epoch, \"training_loss\",(training_loss/s))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testings\n",
    "- testing return ratings (1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Testing_set_error 466.605777415772\n",
      "training_loss 1.0165703211672592\n"
     ]
    }
   ],
   "source": [
    "testing_loss=0\n",
    "s=0.0\n",
    "result=[]\n",
    "for id_users in range(nb_users): \n",
    "    input_=Variable(training_set[id_users]).unsqueeze(0) \n",
    "    target=Variable(testing_set[id_users])\n",
    "    if torch.sum(target.data>0) > 0: # optimize the memory, and in order to compute the loss\n",
    "        output = sae.forward(input_)\n",
    "        target.require_grad=False\n",
    "        output[target==0]=0 # dismiss the data  evaluate model 的 accuracy\n",
    "        result.append(output)\n",
    "        loss=criterion(output,target) # Mean Square Error\n",
    "        mean_corrector = nb_movies / float(torch.sum(target.data>0)+1e-10) # is same as training Phase\n",
    "        testing_loss+=np.sqrt(loss.data[0]*mean_corrector) \n",
    "        #print(loss.data[0]*mean_corrector)\n",
    "        s+=1.0\n",
    "\n",
    "print(\"Whole Testing_set_error\",testing_loss)\n",
    "print(\"training_loss\",(testing_loss/s)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
